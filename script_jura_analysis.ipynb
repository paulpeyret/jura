{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DATA ANALYSIS JURA : Eco-acoustics week\n",
    "MOBI\n",
    "\n",
    "Author : Paul Peyret (13-11-2022)\n",
    "\n",
    "Group : Jure Zeleznik,\n",
    "Loréna Boisseau,\n",
    "Annaïs Soares,\n",
    "Paul Peyret\n",
    "\n",
    "This script analyzes the data recorded using 4 Audiomoths on a transect of different altitude in the forest of Risoux (Jura).\n",
    "\n",
    "This notebook as 3 parts: \n",
    "- PART 1: ACOUSTIC INDICES CALCULATION\n",
    "This part will explore different folders and calculate acousic indices from scikit-maad toolbox and store it into a csv file\n",
    "- PART 2: INDICES ANALYSIS\n",
    "This part load the acoustic indices calculated in PART 1 and do some statistical analysis of a given index on the different points of the transect\n",
    "- PART 3: LONG TERM SPECTROGRAM CALCULATION\n",
    "This part loads all the audio files again in a given point of the transect and calculates the long term average spectrogram (LTSA) at this recording position.\n",
    "\n",
    "Important note: The data were recorded on devices using UTC time. To get local time you must add 2 hours to the datetime string indicated in the name of the wave file.\n",
    "\n",
    "####Prerequisit :\n",
    "\n",
    "Install Python 3.10\n",
    "1) Install packages: \n",
    "`$ pip install -r requirements.txt`\n",
    "2) Copy recording folders in a \"data/\" subfolder in your working directory\n",
    "3) Outputs : \n",
    "    df_indices.csv csv file containing the dataframe with the indicators\n",
    "    out_plot shall be a subfolder of your working directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1 : CALCULATE ACOUSTIC INDICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from maad import sound, features, spl, util\n",
    "from maad.util import plot_features_map\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE INDICES (time consuming)\n",
    "# Prepare dataframe for reading\n",
    "# # ----------  set parameters ------------\n",
    "# User Input\n",
    "usefull_dates_P1=[\"2022-10-05\",\"2022-10-06\"]  # we select only one day\n",
    "allrecPos=['4.1','1.2','10.2','12.2']\n",
    "\n",
    "# ----------  end of set parameters ------------\n",
    "\n",
    "\n",
    "# List files and build dataframe\n",
    "df=pd.DataFrame()\n",
    "path = os.getcwd()\n",
    "fileformat='%Y%m%d_%H%M%S.WAV'\n",
    "\n",
    "# loop over folders to agregate filenames in a big dataframe\n",
    "for config in allrecPos:\n",
    "    dftmp=pd.DataFrame()\n",
    "    recPos=config\n",
    "    subfolder='mobi_am_'+recPos\n",
    "    print(\"Processing \"+subfolder+\"...\")\n",
    "\n",
    "    # Add all filename in the directory in a dataframe\n",
    "    dftmp=pd.DataFrame({\"file\":glob.glob(os.path.join(path, 'data/'+subfolder+'/*.WAV'))})\n",
    "    # another way to do this is filelist = glob(datapath+'/**/*.WAV', recursive = True)'\n",
    "\n",
    "    dftmp['recpos']=recPos\n",
    "    df=pd.concat([df,dftmp])\n",
    "\n",
    "# Extract filename from fullpath\n",
    "df['filename']=df[\"file\"].apply(lambda x: os.path.basename(x))\n",
    "# Extract Date and time from filename\n",
    "df['DateUTC']=df[\"filename\"].apply(lambda x: datetime.strptime(x, fileformat))\n",
    "df['Date']=df[\"DateUTC\"].apply(lambda x: x+timedelta(hours=2))\n",
    "\n",
    "# Set date as index\n",
    "df.set_index('Date', inplace=True)\n",
    "df=df.sort_values(['recpos','Date'])\n",
    "\n",
    "# Remove not usable dates from P1  & Remove not usable dates from P2\n",
    "mask=((df.index > usefull_dates_P1[0]) & (df.index < usefull_dates_P1[1]))\n",
    "df=df[mask]\n",
    "\n",
    "print(df.head())\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% BATCH COMPUTING OF ACOUSTIC INDICES\n",
    "# RUN ONLY ONCE TO GENERATE THE \"df_indices.csv\" FILE\n",
    "\n",
    "# initialize dataframes and indices\n",
    "df_indices = pd.DataFrame() \n",
    "df_indices_per_bin = pd.DataFrame()\n",
    "N=df.shape[0]\n",
    "id=0\n",
    "\n",
    "for index, row in df.iterrows() :\n",
    "    id=id+1\n",
    "    # get the full filename of the corresponding row\n",
    "    fullfilename = row['file']\n",
    "    # Save file basename\n",
    "    path, filename = os.path.split(fullfilename)\n",
    "    print ('\\n**************************************************************')\n",
    "    print(str(id)+\"/\"+str(N))\n",
    "    print (filename)\n",
    "\n",
    "    #### Load the original sound (16bits) and get the sampling frequency fs\n",
    "    try :\n",
    "        wave,fs = sound.load(filename=fullfilename, channel='left', detrend=True, verbose=False)\n",
    "\n",
    "    except:\n",
    "        # Delete the row if the file does not exist or raise a value error (i.e. no EOF)\n",
    "        df.drop(index, inplace=True)\n",
    "        continue\n",
    "\n",
    "    \"\"\" =======================================================================\n",
    "                     Computation in the time domain\n",
    "    ========================================================================\"\"\"\n",
    "\n",
    "    # Parameters of the audio recorder. This is not a mandatory but it allows\n",
    "    # to compute the sound pressure level of the audio file (dB SPL) as a\n",
    "    # sonometer would do.\n",
    "    S = -18         # -18dBV (Audiomoth)\n",
    "    G = 15       # Amplification gain Medium Gain\n",
    "\n",
    "    # compute all the audio indices and store them into a DataFrame\n",
    "    # dB_threshold and rejectDuration are used to select audio events.\n",
    "    df_audio_ind = features.all_temporal_alpha_indices(wave, fs,\n",
    "                                          gain = G, sensibility = S,\n",
    "                                          dB_threshold = 3, rejectDuration = 0.01,\n",
    "                                          verbose = False, display = False)\n",
    "\n",
    "    \"\"\" =======================================================================\n",
    "                     Computation in the frequency domain\n",
    "    ========================================================================\"\"\"\n",
    "\n",
    "    # Compute the Power Spectrogram Density (PSD) : Sxx_power\n",
    "    Sxx_power,tn,fn,ext = sound.spectrogram (wave, fs, window='hann',\n",
    "                                             nperseg = 1024, noverlap=1024//2,\n",
    "                                             verbose = False, display = False,\n",
    "                                             savefig = None)\n",
    "\n",
    "    # compute all the spectral indices and store them into a DataFrame\n",
    "    # flim_low, flim_mid, flim_hi corresponds to the frequency limits in Hz\n",
    "    # that are required to compute somes indices (i.e. NDSI)\n",
    "    # if R_compatible is set to 'soundecology', then the output are similar to\n",
    "    # soundecology R package.\n",
    "    # mask_param1 and mask_param2 are two parameters to find the regions of\n",
    "    # interest (ROIs). These parameters need to be adapted to the dataset in\n",
    "    # order to select ROIs\n",
    "    df_spec_ind, df_spec_ind_per_bin = features.all_spectral_alpha_indices(Sxx_power,\n",
    "                                                            tn,fn,\n",
    "                                                            flim_low = [0,1500],\n",
    "                                                            flim_mid = [1500,8000],\n",
    "                                                            flim_hi  = [8000,48000],\n",
    "                                                            gain = G, sensitivity = S,\n",
    "                                                            verbose = False,\n",
    "                                                            R_compatible = 'soundecology',\n",
    "                                                            mask_param1 = 6,\n",
    "                                                            mask_param2=0.5,\n",
    "                                                            display = False)\n",
    "\n",
    "    \"\"\" =======================================================================\n",
    "                     Create a dataframe\n",
    "    ========================================================================\"\"\"\n",
    "    # First, we create a dataframe from row that contains the date and the\n",
    "    # full filename. This is done by creating a DataFrame from row (ie. TimeSeries)\n",
    "    # then transposing the DataFrame.\n",
    "    df_row = pd.DataFrame(row)\n",
    "    df_row =df_row.T\n",
    "    df_row.index.name = 'Date'\n",
    "    df_row = df_row.reset_index()\n",
    "\n",
    "    # add scalar indices into the df_indices dataframe\n",
    "    df_indices = df_indices.append(pd.concat([df_row,\n",
    "                                              df_audio_ind,\n",
    "                                              df_spec_ind], axis=1))\n",
    "    # add vector indices into the df_indices_per_bin dataframe\n",
    "    #df_indices_per_bin = df_indices_per_bin.append(pd.concat([df_row,\n",
    "    #                                                          df_spec_ind_per_bin], axis=1))\n",
    "# Set back Date as index\n",
    "df_indices = df_indices.set_index('Date')\n",
    "#df_indices_per_bin = df_indices_per_bin.set_index('Date')\n",
    "\n",
    "# SAVE FILE to CSV\n",
    "df_indices.to_csv('df_indices.csv')\n",
    "print('File saved')\n",
    "\n",
    "# %% PLOT FEATURE MAP\n",
    "SPECTRAL_FEATURES=['MEANf','VARf','SKEWf','KURTf','NBPEAKS','LEQf',\n",
    "'ENRf','BGNf','SNRf','Hf', 'EAS','ECU','ECV','EPS_KURT','EPS_SKEW','ACI',\n",
    "'NDSI','rBA','AnthroEnergy','BioEnergy','BI','ROU','ADI','AEI','LFC','MFC','HFC',\n",
    "'ACTspFract','ACTspCount','ACTspMean', 'EVNspFract','EVNspMean','EVNspCount',\n",
    "'TFSD','H_Havrda','H_Renyi','H_pairedShannon', 'H_gamma', 'H_GiniSimpson','RAOQ',\n",
    "'AGI','ROItotal','ROIcover']\n",
    "\n",
    "TEMPORAL_FEATURES=['ZCR','MEANt', 'VARt', 'SKEWt', 'KURTt',\n",
    "               'LEQt','BGNt', 'SNRt','MED', 'Ht','ACTtFraction', 'ACTtCount',\n",
    "               'ACTtMean','EVNtFraction', 'EVNtMean', 'EVNtCount']\n",
    "\n",
    "# plot feature map\n",
    "plot_features_map(df_indices[SPECTRAL_FEATURES], mode='24h')\n",
    "plot_features_map(df_indices[TEMPORAL_FEATURES], mode='24h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 2: INDICES ANALYSIS : ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE DATAFRAME\n",
    "import pandas as pd\n",
    "\n",
    "#%% =================== Load file===========================\n",
    "df_indices=pd.read_csv(\"df_indices.csv\")\n",
    "df_indices.drop('file', inplace=True, axis=1) # drop path column\n",
    "\n",
    "# Retrieve datetime index\n",
    "df_indices[\"Date\"]=pd.to_datetime(df_indices['Date'])\n",
    "df_indices['Time'] = df_indices['Date'].dt.strftime('%H:%M')\n",
    "\n",
    "df_indices.set_index('Date', inplace=True)\n",
    "df_indices=df_indices.sort_values(['recpos','Date'])\n",
    "\n",
    "# Calculate missing H indice\n",
    "df_indices[\"H\"]=df_indices[\"Ht\"]*df_indices[\"Hf\"]\n",
    "# Drop EPS which is not calculated\n",
    "df_indices.drop('EPS',inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIOLIN PLOT : ACI\n",
    "import seaborn as sns\n",
    "\n",
    "# %% ==================Get the Subset of the data frame ==========\n",
    "# ================= user input ===============\n",
    "usefull_dates=[\"2022-10-05\",\"2022-10-06\"] #\n",
    "sel_recopos=['4.1','1.2','10.2','12.2']#['12.2']#['4.1','1.2','10.2','12.2']##['4.1','1.2','10.2','12.2']#[\"CH9\"] # \n",
    "time_sample_per_hour=12 # Integer (there is maximum 12 samples per hour)\n",
    "indexName='ACI' # Name of the index to plot\n",
    "outdir='out_plot/'#'./out_plot/' # your output directory name\n",
    "# ===============end user input ==============\n",
    "\n",
    "#%%=========Violin Plot===========\n",
    "fig=plt.figure()\n",
    "df=df_indices\n",
    "df['recposP'] = df['recpos'].astype('category')\n",
    "df['recposP'] = df['recposP'].map({'4.1': 'P4', '1.2': 'P3', '10.2': 'P2', '12.2': 'P1'})\n",
    "dftmp=df[['recposP',indexName]]\n",
    "dftmp['recposP']=dftmp['recposP'].cat.as_ordered()\n",
    "dftmp['recposP']=dftmp[\"recposP\"].cat.reorder_categories([\"P1\", \"P2\", \"P3\",\"P4\"],ordered=True)\n",
    "dftmp=dftmp.sort_values(by='recposP')\n",
    "\n",
    "my_pal = {\"P1\": \"r\", \"P2\": \"orange\", \"P3\": \"yellow\",\"P4\": \"green\"}\n",
    "\n",
    "sns.violinplot(x=dftmp[\"recposP\"], y=dftmp[indexName],palette=my_pal)\n",
    "if not outdir == \"\":\n",
    "    fig=plt.gcf()\n",
    "    fig.savefig(outdir+'violin_'+indexName+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS\n",
    "import scipy.stats as stats\n",
    "from itertools import combinations\n",
    "\n",
    "combi=list(combinations(sel_recopos,2))\n",
    "df_test=df[['recpos',indexName]]\n",
    "print('\\nMann Whitney U test (Wilcoxon rank sum test)')\n",
    "print(indexName)\n",
    "for c in combi:\n",
    "    print('\\nComparing '+c[0]+' and '+c[1])\n",
    "    dfx1=df_test[df_test['recpos']==c[0]]\n",
    "    dfy1=df_test[df_test['recpos']==c[1]]\n",
    "    # perform two-sided test. You can use 'greater' or 'less' for one-sided test\n",
    "    Statvalue,p=stats.mannwhitneyu(x=dfx1[indexName], y=dfy1[indexName], alternative = 'two-sided')\n",
    "    print(f\"\\nStat = {Statvalue:.1f} \\t p = {p}\")\n",
    "    # output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 3: Long Term Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE DATA\n",
    "from maad import sound, features, spl, util\n",
    "from maad.util import plot_features_map\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------  set parameters ------------\n",
    "# For this experiment, we used a AudioMoth\n",
    "S = -18         # Sensibility of the microphone : -18dBV (Audiomoth)   \n",
    "G = 15       # Total amplification gain in dB (audiomoth medium Gain)\n",
    "VADC = 2        # Voltage range of the analog to digital converter (ADC)\n",
    "\n",
    "fstep=500 # Frequency step in the LTSA\n",
    "fmax=60000 # Maximum frequency of the LTSA\n",
    "Nfft=512 # Nfft for the spectrogram calculation\n",
    "\n",
    "# Selected recording position (change the value to calculate for another recording position)\n",
    "sel_recopos=['10.2']#['4.1','1.2','10.2','12.2']#[\"CH9\"] # \n",
    "# ----------  end of set parameters ------------\n",
    "\n",
    "\n",
    "#%%\n",
    "# First, read df_indices to get the file names\n",
    "df=pd.read_csv(\"df_indices.csv\")\n",
    "# Keep only columns of interest\n",
    "df=df[['Date','file','filename',\"recpos\"]]\n",
    "\n",
    "# Set date as index\n",
    "df[\"Date\"]=pd.to_datetime(df['Date'])\n",
    "df['Time'] = df['Date'].dt.strftime('%H:%M')\n",
    "df.set_index('Date', inplace=True)\n",
    "df=df.sort_values(['recpos','Date'])\n",
    "\n",
    "df['recpos'] = df['recpos'].map(str)  # convert number to strings\n",
    "df=df[df['recpos'].isin(sel_recopos)] \n",
    "df=df.iloc[:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE LTSA\n",
    "# Load and preprocess audio\n",
    "# -------------------------\n",
    "# Then we process all the files found in the directory /indices.\n",
    "# Initialisation of an empty dataframe df_spl to store all the dB SPL values \n",
    "# extracted from the whole audio dataset.\n",
    "\n",
    "df_spl=pd.DataFrame()\n",
    "\n",
    "# Main loop to go through all audio files\n",
    "for index, row in df.iterrows() : \n",
    "    \n",
    "    # initialisation of an empty list to store the dB SPL of the current\n",
    "    # audio recording.\n",
    "    leq_list = []\n",
    "    \n",
    "    # get the full filename of the corresponding row\n",
    "    fullfilename = row['file']\n",
    "    # Save file basename\n",
    "    path, filename = os.path.split(fullfilename)\n",
    "    print ('\\n**************************************************************')\n",
    "    print (filename)\n",
    "    \n",
    "    #### Load the original sound (16bits, only left channel) and get the sampling \n",
    "    # frequency fs\n",
    "    try :\n",
    "        wave,fs = sound.load(filename=fullfilename, channel='left', detrend=True, verbose=False)\n",
    "\n",
    "    except:\n",
    "        print('\\n !! file not found !!')\n",
    "        # Delete the row if the file does not exist or raise a value error (i.e. no EOF)\n",
    "        df.drop(index, inplace=True)\n",
    "        continue\n",
    "    \n",
    "    \"\"\" =======================================================================\n",
    "                     Computation in the frequency domain \n",
    "    ========================================================================\"\"\"\n",
    " \n",
    "    # Compute the Power Spectrogram Density (PSD) : Sxx_power\n",
    "    Sxx_power,tn,fn,ext = sound.spectrogram (wave, fs, window='hann', \n",
    "                                             nperseg = Nfft, noverlap=Nfft/2, \n",
    "                                             verbose = False, display = False, \n",
    "                                             savefig = None)   \n",
    "    \n",
    "    \n",
    "    #### Average PSD (It's a mandatory to compute the mean on the PSD for \n",
    "    # energy conservation)\n",
    "    mean_PSD = np.mean(Sxx_power, axis = 1)\n",
    "    flim=list(range(0,fmax+1,fstep))\n",
    "    labels_leq=[]\n",
    "    for id in range(0,len(flim)-1,1):\n",
    "        #### Compute the Leq of each frequency band\n",
    "        leq_list+=[spl.psd2leq(mean_PSD[util.index_bw(fn,(flim[id],flim[id+1]))], \n",
    "                                gain=G, \n",
    "                                sensitivity=S, \n",
    "                                Vadc=VADC)]\n",
    "        labels_leq+=[str(flim[id]/1000)+'-'+str(flim[id+1]/1000)+'kHz']\n",
    "    \n",
    "    #### Create a dataframe from the list\n",
    "    df_leq = pd.DataFrame([leq_list],\n",
    "                          columns = labels_leq)\n",
    "    \n",
    "    #%\n",
    "    \"\"\" =======================================================================\n",
    "                     Create a dataframe \n",
    "    ========================================================================\"\"\"\n",
    "    #### We create a dataframe from row that contains the date and the \n",
    "    # full filename. This is done by creating a DataFrame from row (ie. TimeSeries)\n",
    "    # then transposing the DataFrame. \n",
    "    df_row = pd.DataFrame(row)\n",
    "    df_row =df_row.T\n",
    "    df_row.index.name = 'Date'\n",
    "    df_row = df_row.reset_index()\n",
    "\n",
    "    #### add Leq values into the df_spl dataframe\n",
    "    df_spl = df_spl.append(pd.concat([df_row, df_leq], axis=1))\n",
    "\n",
    "#### When the loop ends, set Date as index\n",
    "df_spl = df_spl.set_index('Date')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT LTSA\n",
    "outdir='out_plot/'\n",
    "\n",
    "import seaborn as sns\n",
    "# plot using a color palette\n",
    "fig=plt.figure(figsize=[8,5])\n",
    "df_spl_rev = df_spl.iloc[:,::-1].iloc[:,:-4] # reverse dataframe and select only columns with SPL data\n",
    "\n",
    "ax=sns.heatmap(df_spl_rev.iloc[:,:].T,linewidths=0.0,rasterized=True,vmin=20, vmax=70) #cmap=\"YlGnBu\")\n",
    "xlabelid=list(range(0,len(df_spl_rev.index),1))\n",
    "ylabelid=list(range(0,len(flim)+1,1))\n",
    "plt.yticks(ylabelid[0::5],map(str, list(reversed(flim[0::5]))))  # Set text labels.\n",
    "plt.xticks(xlabelid[11::12],df_spl_rev.index[11::12].strftime('%H:%M'))  # Set text labels.\n",
    "plt.title('LTSA '+sel_recopos[0])\n",
    "\n",
    "if not outdir == \"\":\n",
    "    fig=plt.gcf()\n",
    "    fig.savefig(outdir+'_'+'LTSA'+'_'.join(sel_recopos)+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.juravenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46ee55bf6c67bc35214045cfab86d1f204d6ec66378181af21471d23c3264ffe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
